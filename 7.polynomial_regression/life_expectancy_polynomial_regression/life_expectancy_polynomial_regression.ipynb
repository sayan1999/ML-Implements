{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use linear regression to fill in missing values among highly correlated columns in the dataset\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def find_and_impute(x, y):\n",
    "    \n",
    "    tiny_model=LinearRegression()\n",
    "    data=pd.DataFrame(columns=['x', 'y'])\n",
    "    data['x']=x\n",
    "    data['y']=y\n",
    "    \n",
    "    train=data[data['y'].notnull()]      \n",
    "    test=data[data['y'].isnull()]\n",
    "\n",
    "    x_train=pd.DataFrame( train['x'])\n",
    "    y_train=pd.DataFrame(train['y'])\n",
    "    x_test=pd.DataFrame(test['x'])\n",
    "    y_test=pd.DataFrame(test['y'])\n",
    "        \n",
    "    tiny_model.fit(x_train, y_train)\n",
    "    test['y']=tiny_model.predict(x_test)\n",
    "    return train.append(test)['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset/Life Expectancy Data.csv')\n",
    "\n",
    "# target and feature separatation\n",
    "target = ['Life expectancy ']\n",
    "df_x = dataset.drop(columns=target)\n",
    "df_y = pd.DataFrame(dataset[target], columns=target)\n",
    "df_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace strings with integers\n",
    "country_list=df_x.Country.unique().tolist()\n",
    "country_map={k: v for v, k in enumerate(country_list)}\n",
    "\n",
    "status_list=df_x.Status.unique().tolist()\n",
    "status_list={k: v for v, k in enumerate(status_list)}\n",
    "\n",
    "df_x=df_x.replace(country_map).replace(status_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use median to fill-in\n",
    "df_x['Schooling'][df_x['Schooling'].isnull()]=df_x['Schooling'].median()\n",
    "df_x['Polio'][df_x['Total expenditure'].isnull()]=df_x['Total expenditure'].median()\n",
    "df_x['Polio'][df_x['Polio'].isnull()]=df_x['Polio'].median()\n",
    "df_x['Diphtheria '][df_x['Diphtheria '].isnull()]=df_x['Diphtheria '].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find correlation and fill-in\n",
    "df_x['Alcohol']=find_and_impute(df_x['Country'], df_x['Alcohol'])\n",
    "df_x['Population']=find_and_impute(df_x['under-five deaths '], df_x['Population'])\n",
    "df_x['GDP']=find_and_impute(df_x['percentage expenditure'], df_x['GDP'])\n",
    "df_x['Hepatitis B']=find_and_impute(df_x['Diphtheria '], df_x['Hepatitis B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_x.columns:\n",
    "    df_x[column][df_x[column].isnull()]=df_x[column].median()  \n",
    "\n",
    "df_y[target[0]][df_y[target[0]].isnull()]=df_y[target[0]].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardadize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar=StandardScaler()\n",
    "scalar.fit(df_x)\n",
    "s=scalar.transform(df_x)\n",
    "std_df_x = pd.DataFrame(s, columns=df_x.columns)\n",
    "std_df_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing PCA \n",
    "# from sklearn.decomposition import PCA \n",
    "\n",
    "# # Let's say, components = 20\n",
    "# pca = PCA(n_components = 20) \n",
    "# pca.fit(std_df_x) \n",
    "# x_pca = pca.transform(std_df_x) \n",
    "\n",
    "# std_df_x=pd.DataFrame(x_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(std_df_x, df_y[target[0]], test_size = 0.25, random_state = 55)\n",
    "\n",
    "#use polynomial(higher order) features\n",
    "#tune the degree-parameter below, for me degree=2 worked the best without overfitting the data\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "x_train=poly_features.fit_transform(x_train)\n",
    "x_test=poly_features.fit_transform(x_test)\n",
    "\n",
    "#linear regression on polynomial features\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model=LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#predict values\n",
    "y_predict = pd.Series(model.predict(x_test), index=y_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"Model Score: \", model.score(x_train, y_train))\n",
    "print(\"R2 Score: \", r2_score(y_test, y_predict))\n",
    "print(\"Mean Squared error: \", MSE(y_test, y_predict))\n",
    "print(\"Percentage Mean Squared error: \", 100*MSE(y_test, y_predict)/y_test.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.style.use('dark_background')\n",
    "plt.plot(range(y_predict.size), (y_predict-y_test)**2)\n",
    "plt.title(\"MSE per index\")\n",
    "plt.xlabel(\"index\")\n",
    "plt.ylabel('squared error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze large errors (deviation > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_error=(y_predict-y_test).abs() > 10\n",
    "high_error=high_error.loc[high_error==True]\n",
    "error_analysis = dataset.iloc[high_error.index.array]\n",
    "error_analysis['error'] = high_error\n",
    "error_analysis['predicted'] = y_predict.loc[high_error.index]\n",
    "error_analysis['MSE'] = error_analysis['predicted']-error_analysis['Life expectancy ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis.sort_values('MSE')['MSE']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
